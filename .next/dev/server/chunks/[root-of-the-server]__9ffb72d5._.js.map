{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 70, "column": 0}, "map": {"version":3,"sources":["file:///C:/game/IIITH/src/lib/db.ts"],"sourcesContent":["import { PrismaClient } from '@prisma/client'\n\nconst globalForPrisma = globalThis as unknown as {\n  prisma: PrismaClient | undefined\n}\n\nexport const db =\n  globalForPrisma.prisma ??\n  new PrismaClient({\n    log: ['query'],\n  })\n\nif (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = db"],"names":[],"mappings":";;;;AAAA;;AAEA,MAAM,kBAAkB;AAIjB,MAAM,KACX,gBAAgB,MAAM,IACtB,IAAI,sMAAY,CAAC;IACf,KAAK;QAAC;KAAQ;AAChB;AAEF,wCAA2C,gBAAgB,MAAM,GAAG"}},
    {"offset": {"line": 93, "column": 0}, "map": {"version":3,"sources":["file:///C:/game/IIITH/src/app/api/documents/upload/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server'\nimport { writeFile, mkdir } from 'fs/promises'\nimport { existsSync } from 'fs'\nimport path from 'path'\nimport { createRequire } from 'module'\nimport { db } from '@/lib/db'\n\nexport const runtime = 'nodejs'\n\n// ðŸ‘‡ REQUIRED for pdf-parse (CJS)\nconst require = createRequire(import.meta.url)\nconst pdfParse = require('pdf-parse')\n\nexport async function POST(request: NextRequest) {\n  try {\n    const formData = await request.formData()\n    const file = formData.get('file') as File | null\n\n    if (!file) {\n      return NextResponse.json({ error: 'No file provided' }, { status: 400 })\n    }\n\n    const uploadsDir = path.join(process.cwd(), 'uploads')\n    if (!existsSync(uploadsDir)) {\n      await mkdir(uploadsDir, { recursive: true })\n    }\n\n    const buffer = Buffer.from(await file.arrayBuffer())\n\n    const filePath = path.join(uploadsDir, file.name)\n    await writeFile(filePath, buffer)\n\n    // âœ… PDF TEXT EXTRACTION (STABLE)\n    const pdfData = await pdfParse(buffer)\n    const text: string = pdfData.text || ''\n\n    if (!text.trim()) {\n      throw new Error('PDF text extraction failed')\n    }\n\n    // Save document\n    const document = await db.document.create({\n      data: { name: file.name }\n    })\n\n    // Chunk text\n    const chunks = text\n      .split('\\n')\n      .map(t => t.trim())\n      .filter(t => t.length > 40)\n\n    for (const content of chunks) {\n      await db.chunk.create({\n        data: { content }\n      })\n    }\n\n    return NextResponse.json({\n      success: true,\n      documentId: document.id,\n      chunks: chunks.length\n    })\n  } catch (error) {\n    console.error('UPLOAD ERROR:', error)\n    return NextResponse.json(\n      { error: 'Failed to process PDF' },\n      { status: 500 }\n    )\n  }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AAEO,MAAM,UAAU;AAEvB,kCAAkC;AAClC,MAAM,UAAU,IAAA,sHAAa,EAAC,8BAAY,GAAG;AAC7C,MAAM;AAEC,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,WAAW,MAAM,QAAQ,QAAQ;QACvC,MAAM,OAAO,SAAS,GAAG,CAAC;QAE1B,IAAI,CAAC,MAAM;YACT,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAmB,GAAG;gBAAE,QAAQ;YAAI;QACxE;QAEA,MAAM,aAAa,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;QAC5C,IAAI,CAAC,IAAA,2GAAU,EAAC,aAAa;YAC3B,MAAM,IAAA,8HAAK,EAAC,YAAY;gBAAE,WAAW;YAAK;QAC5C;QAEA,MAAM,SAAS,OAAO,IAAI,CAAC,MAAM,KAAK,WAAW;QAEjD,MAAM,WAAW,4GAAI,CAAC,IAAI,CAAC,YAAY,KAAK,IAAI;QAChD,MAAM,IAAA,kIAAS,EAAC,UAAU;QAE1B,iCAAiC;QACjC,MAAM,UAAU,MAAM,SAAS;QAC/B,MAAM,OAAe,QAAQ,IAAI,IAAI;QAErC,IAAI,CAAC,KAAK,IAAI,IAAI;YAChB,MAAM,IAAI,MAAM;QAClB;QAEA,gBAAgB;QAChB,MAAM,WAAW,MAAM,wHAAE,CAAC,QAAQ,CAAC,MAAM,CAAC;YACxC,MAAM;gBAAE,MAAM,KAAK,IAAI;YAAC;QAC1B;QAEA,aAAa;QACb,MAAM,SAAS,KACZ,KAAK,CAAC,MACN,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI,IACf,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,GAAG;QAE1B,KAAK,MAAM,WAAW,OAAQ;YAC5B,MAAM,wHAAE,CAAC,KAAK,CAAC,MAAM,CAAC;gBACpB,MAAM;oBAAE;gBAAQ;YAClB;QACF;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,YAAY,SAAS,EAAE;YACvB,QAAQ,OAAO,MAAM;QACvB;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,iBAAiB;QAC/B,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}